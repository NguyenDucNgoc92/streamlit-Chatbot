import streamlit as st
import requests
import json
import time

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="NDN AI Pro", page_icon="üíé", layout="wide")

# --- CSS CUSTOM (HI·ªÜU ·ª®NG ƒê·∫∏P) ---
st.markdown("""
<style>
    /* Hi·ªáu ·ª©ng Fade In cho tin nh·∫Øn */
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    .stChatMessage {
        animation: fadeIn 0.5s ease-out;
    }
    
    /* T√πy ch·ªânh ti√™u ƒë·ªÅ link */
    .main-title {
        font-size: 3rem;
        font-weight: 800;
        background: -webkit-linear-gradient(45deg, #4158D0, #C850C0, #FFCC70);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 2rem;
    }
    
    /* Bo g√≥c cho khung chat */
    .stChatFloatingInputContainer {
        bottom: 20px;
    }
    
    /* Sidebar styling */
    section[data-testid="stSidebar"] {
        background-color: #f8f9fa;
        border-right: 1px solid #e0e0e0;
    }
</style>
""", unsafe_allow_html=True)

# --- 1. MODAL ƒêI·ªÄU KHO·∫¢N ---
if "agreed" not in st.session_state:
    st.session_state.agreed = False

@st.dialog("‚ö†Ô∏è QUY ƒê·ªäNH S·ª¨ D·ª§NG AN TO√ÄN")
def show_terms():
    st.warning("Vui l√≤ng ƒë·ªçc k·ªπ tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu")
    st.markdown("""
    - **KH√îNG CHIA S·∫∫ D·ªÆ LI·ªÜU C√Å NH√ÇN**: Kh√¥ng nh·∫≠p m·∫≠t kh·∫©u, s·ªë th·∫ª t√≠n d·ª•ng ho·∫∑c th√¥ng tin nh·∫°y c·∫£m.
    - **M·ª§C ƒê√çCH**: S·ª≠ d·ª•ng cho tr·∫£i nghi·ªám m√¥ ph·ªèng, h·ªçc t·∫≠p v√† nghi√™n c·ª©u.
    - **THANH TO√ÅN**: ƒê√¢y l√† phi√™n b·∫£n mi·ªÖn ph√≠, ho√†n to√†n **kh√¥ng y√™u c·∫ßu thanh to√°n**.
    - **H·ªÜ TH·ªêNG**: S·ª≠ d·ª•ng c√¥ng ngh·ªá Groq Llama 3 API.
    """)
    if st.button("T√¥i ƒë·ªìng √Ω v√† cam k·∫øt tu√¢n th·ªß", use_container_width=True, type="primary"):
        st.session_state.agreed = True
        st.rerun()

if not st.session_state.agreed:
    show_terms()
    st.stop()

# --- 2. GIAO DI·ªÜN CH√çNH ---
st.markdown('<div class="main-title"><a href="https://nguyenducngoc.vn/" target="_blank" style="text-decoration: none; color: inherit;">NDN</a> AI ASSISTANT</div>', unsafe_allow_html=True)

# L·∫•y key
GROQ_API_KEY = st.secrets["GROQ_API_KEY"]

# Kh·ªüi t·∫°o session state
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- SIDEBAR N√ÇNG C·∫§P ---
with st.sidebar:
    st.image("https://img.icons8.com/fluency/96/artificial-intelligence.png", width=80)
    st.title("Control Center")
    if st.button("üÜï T·∫°o h·ªôi tho·∫°i m·ªõi", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
    
    st.divider()
    st.caption("Phi√™n b·∫£n: Pro 2.0 (Llama 3.3)")
    st.info("H·ªá th·ªëng t·ª± ƒë·ªông t·ªëi ∆∞u h√≥a c√¢u tr·∫£ l·ªùi d·ª±a tr√™n ng·ªØ c·∫£nh.")

# --- 3. HI·ªÇN TH·ªä TIN NH·∫ÆN V·ªöI HI·ªÜU ·ª®NG ---
for i, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        # N√∫t s·ª≠a prompt cho tin nh·∫Øn cu·ªëi c√πng c·ªßa User
        if i == len(st.session_state.messages) - 2 and message["role"] == "user":
            col1, col2 = st.columns([1, 5])
            with col1:
                if st.button("‚úèÔ∏è S·ª≠a", key=f"edit_{i}", help="Ch·ªânh s·ª≠a c√¢u h·ªèi n√†y"):
                    st.session_state.edit_input = message["content"]
                    # (T√≠nh nƒÉng s·ª≠a s·∫Ω ƒë∆∞·ª£c x·ª≠ l√Ω qua logic session)

# --- 4. X·ª¨ L√ù CHAT ---
if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi t·∫°i ƒë√¢y..."):
    # L∆∞u tin nh·∫Øn ng∆∞·ªùi d√πng
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Hi·ªÉn th·ªã Assistant ph·∫£n h·ªìi
    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_response = ""
        
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": "llama-3.3-70b-versatile",
            "messages": [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
            "stream": True 
        }

        try:
            response = requests.post(
                "https://api.groq.com/openai/v1/chat/completions",
                headers=headers, json=payload, stream=True
            )
            
            for line in response.iter_lines():
                if line:
                    line_text = line.decode("utf-8")
                    if line_text.startswith("data: "):
                        data_str = line_text[6:]
                        if data_str == "[DONE]": break
                        data_json = json.loads(data_str)
                        delta = data_json["choices"][0]["delta"].get("content", "")
                        full_response += delta
                        # Th√™m icon con tr·ªè nh·∫•p nh√°y
                        placeholder.markdown(full_response + " ‚ñà")
            
            placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            st.error(f"‚ö†Ô∏è C√≥ l·ªói x·∫£y ra: {str(e)}")
